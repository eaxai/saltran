{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zyhwHIPUwvmt",
    "outputId": "342edc8b-76e0-4e3b-876b-bd4e17f4f9db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AV2sUavI0DIT",
    "outputId": "7be045bc-32d2-476c-fb03-32cf685206d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: self_attention_cv in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from self_attention_cv) (1.19.0)\n",
      "Requirement already satisfied: einops>=0.3 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from self_attention_cv) (0.3.0)\n",
      "Requirement already satisfied: torchvision>=0.8 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from self_attention_cv) (0.9.1)\n",
      "Requirement already satisfied: pytest>=6.2 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from self_attention_cv) (6.2.4)\n",
      "Requirement already satisfied: torch>=1.7 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from self_attention_cv) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from torchvision>=0.8->self_attention_cv) (7.2.0)\n",
      "Requirement already satisfied: iniconfig in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (0.13.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (19.3.0)\n",
      "Requirement already satisfied: packaging in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (20.4)\n",
      "Requirement already satisfied: toml in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (0.10.2)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from pytest>=6.2->self_attention_cv) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from torch>=1.7->self_attention_cv) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from packaging->pytest>=6.2->self_attention_cv) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/eax/miniconda3/envs/b/lib/python3.8/site-packages (from packaging->pytest>=6.2->self_attention_cv) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install self_attention_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwWuvks4LYLF"
   },
   "outputs": [],
   "source": [
    " !cp /content/drive/MyDrive/SalTran/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dvgZAqJ_xJHJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from self_attention_cv.vit import ResNet50ViT\n",
    "from utils import corr_coeff, kld_loss, nss, train_val_dataset\n",
    "from saltran import SalTran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9b2FBpE1YBc",
    "outputId": "ccc2a9be-22d3-4f0f-c06e-061883082c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-PzByDhkCBW",
    "outputId": "53830db7-398d-43f3-87ec-b6ce12223058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x102a97250>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9edPpxdX0dUT"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l5Uv6zVYxw7U"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import mit1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1lsLKLzx5wz",
    "outputId": "b5cf059e-ca02-4c0d-ede2-ee90f297714d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mit1003' from '/Users/eax/worx/deeplearning/attn/saltran/mit1003.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mit1003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHVUmaXj08PN",
    "outputId": "bd050d0a-903d-4b9a-9e01-dbf9ad22d3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 501, 'val': 502}\n"
     ]
    }
   ],
   "source": [
    "dataset = mit1003.MIT1003Data('./MIT1003/', 'ALLSTIMULI', 'ALLFIXATIONMAPS')\n",
    "ds = train_val_dataset(dataset)\n",
    "dataloaders = {x: torch.utils.data.DataLoader(ds[x], batch_size=1,\n",
    "                        shuffle=True, num_workers=0)\n",
    "        for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(ds[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFSgtMQDVfnh",
    "outputId": "72822152-3278-43e5-e9e6-ad9608426f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1179039478302, 2.640000104904175, 0.2665327787399292, 1.3819854259490967\n",
      "0.0, 0.9607843160629272, 0.031963273882865906, 0.10231802612543106\n",
      "./MIT1003/ALLSTIMULI/i1429004931.jpeg\n",
      "./MIT1003/ALLFIXATIONMAPS/i1429004931_fixPts.jpg\n",
      "./MIT1003/ALLFIXATIONMAPS/i1429004931_fixMap.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eax/miniconda3/envs/b/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = ds['train']\n",
    "i = train[32]['img']\n",
    "f = train[32]['fix']\n",
    "m = train[32]['map']\n",
    "n = train[32]['name']\n",
    "nf = train[32]['fname']\n",
    "nm = train[32]['mname']\n",
    "print(f'{i.min()}, {i.max()}, {i.mean()}, {i.std()}')\n",
    "print(f'{m.min()}, {m.max()}, {m.mean()}, {m.std()}')\n",
    "print(f'{n}')\n",
    "print(f'{nf}')\n",
    "print(f'{nm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NtgEMzStVgRp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(1.) tensor(0.5093) tensor(0.3133)\n",
      "tensor(-2.1179) tensor(2.6400) tensor(0.2666) tensor(1.3760)\n",
      "tensor(0.) tensor(0.9608) tensor(0.0320) tensor(0.1023)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from utils import normalize_tensor\n",
    "import cv2\n",
    "i = Image.open(n)#.convert('L')\n",
    "ij = transforms.Compose([\n",
    "  transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "ixj = ij(i)\n",
    "print(ixj.min(), ixj.max(), ixj.mean(), ixj.std())\n",
    "it = transforms.Compose([\n",
    "  transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "ix = it(i)\n",
    "print(ix.min(), ix.max(), ix.mean(), ix.std())\n",
    "im = Image.open(nm)\n",
    "mt = transforms.Compose([\n",
    "  transforms.Resize((64, 64)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "mx = mt(im)\n",
    "fi = Image.open(nf).convert('1')\n",
    "ft = transforms.Compose([\n",
    "  transforms.Resize((256, 256)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "ixf = ft(fi)\n",
    "print(mx.min(), mx.max(), mx.mean(), mx.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4T7X-d_PvTUj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'saltran' from '/Users/eax/worx/deeplearning/attn/saltran/saltran.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import saltran\n",
    "importlib.reload(saltran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EWkRnkuZHwXy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalTran(\n",
       "  (xformer): ResNet50ViT(\n",
       "    (model): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ViT(\n",
       "        (project_patches): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (emb_dropout): Dropout(p=0, inplace=False)\n",
       "        (mlp_head): Linear(in_features=512, out_features=10, bias=True)\n",
       "        (transformer): TransformerEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): TransformerBlock(\n",
       "              (mhsa): MultiHeadSelfAttention(\n",
       "                (to_qvk): Linear(in_features=512, out_features=768, bias=False)\n",
       "                (W_0): Linear(in_features=256, out_features=512, bias=False)\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "              (norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (linear): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0, inplace=False)\n",
       "                (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (4): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (salmap): Sequential(\n",
       "    (0): Unflatten(dim=2, unflattened_size=(64, 64))\n",
       "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = saltran.SalTran()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7OVJmeAjekhV"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwWPQcxgH8MT"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "barzero = tqdm(range(5), position=0, leave=True)\n",
    "print(\"---\")\n",
    "\n",
    "for epoch in barzero:\n",
    "  for phase in ['train', 'val']:\n",
    "    if phase == 'train':\n",
    "      model.train()\n",
    "    else:\n",
    "      model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    bar = tqdm(dataloaders[phase], desc=phase, position=0, leave=True)\n",
    "    for data in bar:\n",
    "      imgs = data['img'].float().to(device)\n",
    "      fiks = data['fix'].to(device)\n",
    "      maps = data['map'].float().to(device)\n",
    "      name = data['name']\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      with torch.set_grad_enabled(phase == 'train'):\n",
    "        outs = model(imgs)\n",
    "        losses = []\n",
    "        kl = kld_loss(outs, maps)\n",
    "        ns = nss(outs, fiks)\n",
    "        cc = corr_coeff(outs, maps)\n",
    "        print(f'kl is nan for {name}') if math.isnan(kl) else None\n",
    "        print(f'nss is nan for {name}') if math.isnan(ns) else None\n",
    "        print(f'cc is nan for {name}') if math.isnan(cc) else None\n",
    "        losses.append(kl)\n",
    "        losses.append(ns)\n",
    "        losses.append(cc)\n",
    "        losses = [l.mean(1).mean(0) for l in losses]\n",
    "        loss_weights = [1, 1, 1]\n",
    "        loss = sum(weight * l for weight, l in\n",
    "                              zip(loss_weights, losses))\n",
    "        if phase == 'train':\n",
    "          bar.set_description(f'{outs.min():.2f}, {outs.max():.2f}, {outs.mean():.2f}, {outs.std():.2f} - loss: {loss.item():.5f}')\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "      running_loss += loss.item() * imgs.size(0)\n",
    "    \n",
    "\n",
    "    if phase == 'train':\n",
    "      scheduler.step()\n",
    "\n",
    "  epoch_loss = running_loss / dataset_sizes[phase]\n",
    "  print(f'\\nEpoch Loss: {epoch_loss:.5f} Running Loss: {running_loss:.5f}')\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8NeR30AVbdi"
   },
   "outputs": [],
   "source": [
    "!cp ./*.py /content/drive/MyDrive/SalTran/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDfW_RlKJ6zw"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=10):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(dataloaders['val']):\n",
    "            inputs = inputs['img'].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted')\n",
    "                imshow(outputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAG6VKwCehNv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGUMnoKAfaWU"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp[:, :, 0], cmap='gray')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O84gtggfebfN"
   },
   "outputs": [],
   "source": [
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FGss9uKed5q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "saltran.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
